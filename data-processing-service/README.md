# Сервис обработки данных социальных сетей

Сервис для обработки и анализа данных из различных социальных сетей, включая нормализацию данных, обработку в реальном времени и пакетную обработку.

## Основные возможности

- Нормализация данных из различных социальных сетей (Telegram, Twitter, VK)
- Обработка данных в реальном времени с использованием Kafka
- Пакетная обработка данных с использованием Apache Spark
- Кэширование результатов с использованием Redis
- REST API для получения аналитических данных
- Мониторинг и метрики
- Расширенная аналитика:
  - Расчет коэффициента вовлеченности (ER)
  - Анализ пиковых часов активности
  - Географический анализ аудитории
  - Анализ тональности текстов
  - Обнаружение трендов и аномалий
  - Кластеризация тем

## Технологии

- Python 3.9
- Flask
- Apache Spark
- Kafka
- Redis
- Docker
- Pandas
- NumPy
- TensorFlow
- scikit-learn
- Transformers (BERT)

## Требования

- Docker и Docker Compose
- Python 3.9+
- JDK 11 (для Apache Spark)
- CUDA (опционально, для GPU-ускорения)

## Установка и запуск

1. Клонируйте репозиторий:
```bash
git clone <repository-url>
cd data-processing-service
```

2. Создайте файл .env на основе .env.example:
```bash
cp .env.example .env
```

3. Настройте переменные окружения в файле .env

4. Запустите сервис с помощью Docker Compose:
```bash
docker-compose up --build
```

## API Endpoints

### Базовые метрики
```
GET /api/channel/{channel_id}/metrics
GET /api/channel/{channel_id}/weekly-report
GET /api/channel/{channel_id}/hashtags
GET /api/channel/{channel_id}/engagement-trends
GET /api/channel/{channel_id}/realtime
```

### Расширенная аналитика
```
GET /api/channel/{channel_id}/engagement-rate
GET /api/channel/{channel_id}/peak-hours
GET /api/channel/{channel_id}/geography
POST /api/channel/{channel_id}/sentiment
GET /api/channel/{channel_id}/trends
GET /api/channel/{channel_id}/topics
```

### Утилиты
```
POST /api/normalize
POST /api/channel/{channel_id}/cache/invalidate
```

## Расширенная аналитика

### Коэффициент вовлеченности (ER)
- Формула: (лайки + репосты + комментарии) / подписчики * 100%
- Периодичность обновления: каждый час
- Кэширование: 1 час

### Пиковые часы активности
- Анализ времени публикации самых популярных постов
- Группировка по часам
- Расчет среднего количества взаимодействий
- Периодичность обновления: ежедневно
- Кэширование: 24 часа

### Географический анализ
- Распределение аудитории по странам/городам
- Процентное соотношение
- Статистика активности по регионам
- Периодичность обновления: ежедневно
- Кэширование: 24 часа

### Анализ тональности
- Использование BERT для анализа текстов
- Определение позитивной/негативной тональности
- Оценка уверенности модели
- Результаты в реальном времени
- Без кэширования

### Обнаружение трендов
- Кластеризация текстов
- Выявление аномалий в активности
- Расчет z-score для определения выбросов
- Периодичность обновления: каждый час
- Кэширование: 1 час

### Кластеризация тем
- Группировка похожих постов
- Определение ключевых слов для каждого кластера
- Анализ размера кластеров
- Периодичность обновления: ежедневно
- Кэширование: 24 часа

## Разработка

### Локальная разработка

1. Создайте виртуальное окружение:
```bash
python -m venv venv
source venv/bin/activate  # для Linux/Mac
venv\Scripts\activate     # для Windows
```

2. Установите зависимости:
```bash
pip install -r requirements.txt
```

3. Запустите сервис:
```bash
python app.py
```

### Тестирование

Запуск тестов:
```bash
pytest
```

## Мониторинг

Сервис предоставляет метрики в формате Prometheus по адресу `/metrics`.

## Лицензия

MIT 